Time I have spent on this project:
Feb 5, 8-12, 15-19, 22-24, March 5, 16, April 9th, 16th, 20th

(Updated on 4/21/21)
Hours: ~100

Basic premise of what I have been working on for each day
5th; Think about what metrics I want to have in my algorithm. Which stats would BEST tell me which leads become customers

8th-10th; Read in the initial dataset. Look through it and see that it is AWFUL (big shock I know) do my best to clean it, 
    get rid of unnecessary data, or somehow change it to be more accurate to the column it is in (I don't believe there is a zip code
    called 'poasoejfpo','????', or 'hotmail.com')

11th-12th; Once the data is in a good enough spot to be worked with, start making the very first machine learning algorithm. Start with
    descision tree and go from there. Change some things in the data set or how I feed the data into the algorithm. Try an XKBoost
    next.

15th-17th; Feel confident that the model I made can accurately predict which leads turn into customers. Fail. Get stopped immedieatly
    by how starkly different the data is from the testing data. Feel bad about myself. 

18th-19th, 22-24th; Feel better about myself because my manager wants me to get some different numbers aobut leads and reps. Think
    about how I can use these new numbers to better my old algorithms. Start working on getting the 'Speed to Contact' numbers and
    the 'Time to Appointment' numbers. Use those for the main work project AND my new machine learning algorithms.  

Mar 5th; Spent an hour working through the dataset and tried to merge the speed to contact data with it

Mar 16th; I started working on my Network again. I tried changing the 
    epochs to be less or more, I changed the number of units in 
    a dense layer, I change the 'verbose' setting on my 'model.fit'
    and I cannot seem to get my accuracy above 0.501. I found
    a tutorial on structured data in the TensorFlow tutorials, so
    maybe that will help me get what I want. We will see.

March 17th; I cleaned up the datasets I have been working with so 
    it would not include any personal info. Now I am free to share
    it as I need to. 

April 9th, 16th, 19th,; As I looked through the analytics section of the Luminary app, I noticed I was not using 
    a bunch of numbers that could add great value to regressions and algorithims that I could make. So, I decided
    I wanted to add number of calls, number of leads claimed, appointments set, number of dials, talk time, and
    number of sales. As I went to get that information from the database, I have been unsuccessful. For whatever reason, 
    the JOINs of the tables lead_products, call_logs, appointments, and status_history. It is probably because 
    those tables are all massive... but still I am getting very spectific pieces of data from each table so it 
    shouldn't be too much to grab. I don't understand.

April 20th; I was finally able to get the data I wanted in a good format.
    It took some doing and some fancy wrangling of four different tables,
    but I got it. I set up the format to make it work with my simple 
    Nueral Network I made and it... didn't work? I say it like this
    because I got a result but, down to the 20th decimal place, it 
    is the exact same number that I got from the different set of
    data I used. So... really don't know what is going on here. I decided
    to completely change my network. I am starting to work with TensorFlow's
    tutorial on Structured Data along with classifying structured data
    with feature columns. We shall see what happens

April 21st; 